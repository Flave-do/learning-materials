开源异步网络框架（同时去爬取）

爬虫流程

1、获取url

2、通过requests发送请求

3、解析响应

【有详情页要爬取详情页数据----url---2.---3.---4.

4.保存数据



开启scrapy

scrapy crawl sixstartText

命令后面加 	--nolog		可以隐藏多余提示、包括报错

scrapy crawl sixstartText --nolog



提取数据:

​	·response.xpath方法的结果是一个类似的类型，包含的是selector对象，操作和列表一样但还有额外方法

​	eg  :  response.xpath('sdf/fsdf/avi[*]').getall()

​	·get()一个

​	·getall()获取所有的

​	·extract() 反回一个包含有字符串的列表

​	·extract_first()  反回列表第一个字符串，列表为空反回None