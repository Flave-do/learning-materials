```
# 反爬
# 我们是爬虫 服务器上的代码就会识别我们的爬虫 反爬
# 1. 判断请求头来进行反爬 User-agent【大部分网站都会验证】 referfer[图片，视频，音频] cookie【登陆】
# 解决：加上headers 填写从网页上复制粘贴的请求头
# 2.根据用户的行为进行反爬
# a.请求频率过高 一分钟爬60次   解决：使用time.sleep()
# b.页面中设置一些陷阱 正常用户访问是没有的 爬虫访问是有的 百度搜索  解决：分析好网站再爬
# 3.js加密
# 解决：分析js代码 看一下加密的数据是怎么来的
# 4.字体加密
# 解决：需要下载字体文件 用到一些工具 查看字体文件的命名
# 5.验证码
# a.数字字母验证码 解决：使用打码平台
# b.滑动解锁 从左滑到右 解锁 使用selenium

# 打码平台：用来解决验证码 图片验证码 不需要自己写相关代码 直接调用别人的接口就可以了
# 超级鹰（付费） 百度文字识别（文字识别，可以识别验证 效果不太理想） 云打码
# 别人写的数据 代码 第三方库 不要去改
```

--------------

无限debugg	: 反扒

set-cookie 	： 可能需要cookie信息

无痕里面复制cookie会更有效....

