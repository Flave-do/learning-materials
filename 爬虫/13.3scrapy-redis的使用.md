分布式爬虫

必须共有一个队列，我去url中拿数据，你去url中拿数据

指纹：唯一

redis连接命令：

redis-cli -h 192.168.1.167 -p 6379

-h ip 连接远程电脑的ip

-p 端口号



scrapy-redis	分布式   继承就可以使用  比较方便

# slaver端

​		去master端拿任务  去爬取数据  在爬取过程中可以生成新的任务  获取的新任务给到master端

--------

# master端

​		用到redis数据库  slaver端给的任务  先进行去重	再加入到待爬取的队列中

----------

queue	队列   先进先出





SCHEDULER = 									设置调度器

DUPEFILTER_CLASS = 						过滤模块

SCHEDULER_PERSIST = True			当爬虫结束时是否保持redis队列

断点续爬  任务提前结束下次可以继续爬